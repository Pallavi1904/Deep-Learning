{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe2c8c7-9d19-4a7b-ae2b-a4032b0dbd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e56d619-6e12-41a6-810a-79cd652fe603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Datasets/Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b63b3f-bc1b-436b-ac4b-2464175909ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73d23af4-ea54-4514-82b8-76ddc45fedd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Surname\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fba7f69-199f-4776-91d0-0b58e49ca040",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"RowNumber\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "020fcfa7-24e8-4e43-b206-a8e367548986",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"CustomerId\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2815045b-0c50-4868-8688-4100eb293f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Geography\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3478cf1a-7856-46fb-bc3f-83df36632c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Gender\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7905f3ca-fa63-4e0e-a2f5-f3f1ba557ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Balance\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dc24b39-9b6b-4a85-9574-1c0230966287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          619   42       2              1          1               1   \n",
       "1          608   41       1              1          0               1   \n",
       "2          502   42       8              3          1               0   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13a5f2cd-28c0-4597-8382-3b68534ce379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        0\n",
       "Age                0\n",
       "Tenure             0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35066d5f-4e9e-45ac-aacc-c8c3307d061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = df.iloc[:,:-1]\n",
    "output_data = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eb13f7e-5d3d-46af-8dc3-8d1280cbbf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4fce05e-79db-4847-a9d5-ddcbfa5aeb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32622142,  0.29351742, -1.04175968, ...,  0.64609167,\n",
       "         0.97024255,  0.02188649],\n",
       "       [-0.44003595,  0.19816383, -1.38753759, ..., -1.54776799,\n",
       "         0.97024255,  0.21653375],\n",
       "       [-1.53679418,  0.29351742,  1.03290776, ...,  0.64609167,\n",
       "        -1.03067011,  0.2406869 ],\n",
       "       ...,\n",
       "       [ 0.60498839, -0.27860412,  0.68712986, ..., -1.54776799,\n",
       "         0.97024255, -1.00864308],\n",
       "       [ 1.25683526,  0.29351742, -0.69598177, ...,  0.64609167,\n",
       "        -1.03067011, -0.12523071],\n",
       "       [ 1.46377078, -1.04143285, -0.35020386, ...,  0.64609167,\n",
       "        -1.03067011, -1.07636976]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.fit_transform(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aee63f0f-c2a4-4b7a-a26c-6900fe3c8993",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.DataFrame(ss.fit_transform(input_data), columns=input_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92dea975-3a8d-4e35-a36a-5838adf9cc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.326221</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-1.041760</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.021886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.440036</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.216534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.536794</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>1.032908</td>\n",
       "      <td>2.527057</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>0.240687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501521</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.108918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.063884</td>\n",
       "      <td>0.388871</td>\n",
       "      <td>-1.041760</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-0.365276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.246488</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-0.004426</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.066419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-1.391939</td>\n",
       "      <td>-0.373958</td>\n",
       "      <td>1.724464</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.027988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.604988</td>\n",
       "      <td>-0.278604</td>\n",
       "      <td>0.687130</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-1.008643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.256835</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-0.695982</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.125231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.463771</td>\n",
       "      <td>-1.041433</td>\n",
       "      <td>-0.350204</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-1.076370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age    Tenure  NumOfProducts  HasCrCard  \\\n",
       "0       -0.326221  0.293517 -1.041760      -0.911583   0.646092   \n",
       "1       -0.440036  0.198164 -1.387538      -0.911583  -1.547768   \n",
       "2       -1.536794  0.293517  1.032908       2.527057   0.646092   \n",
       "3        0.501521  0.007457 -1.387538       0.807737  -1.547768   \n",
       "4        2.063884  0.388871 -1.041760      -0.911583   0.646092   \n",
       "...           ...       ...       ...            ...        ...   \n",
       "9995     1.246488  0.007457 -0.004426       0.807737   0.646092   \n",
       "9996    -1.391939 -0.373958  1.724464      -0.911583   0.646092   \n",
       "9997     0.604988 -0.278604  0.687130      -0.911583  -1.547768   \n",
       "9998     1.256835  0.293517 -0.695982       0.807737   0.646092   \n",
       "9999     1.463771 -1.041433 -0.350204      -0.911583   0.646092   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  \n",
       "0           0.970243         0.021886  \n",
       "1           0.970243         0.216534  \n",
       "2          -1.030670         0.240687  \n",
       "3          -1.030670        -0.108918  \n",
       "4           0.970243        -0.365276  \n",
       "...              ...              ...  \n",
       "9995       -1.030670        -0.066419  \n",
       "9996        0.970243         0.027988  \n",
       "9997        0.970243        -1.008643  \n",
       "9998       -1.030670        -0.125231  \n",
       "9999       -1.030670        -1.076370  \n",
       "\n",
       "[10000 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99a62ea8-f024-4fc9-9687-6e1380e2a49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41fe70d5-428e-4d1f-93e2-5f412cc8754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input_data, output_data,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbba0a76-57ed-4c66-89a4-f7a6911eb924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8de388f-90e1-4cb3-8270-f40e5221841d",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c60edd71-2ab9-4c1d-85f7-269919a0eb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PALLAVI\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aea227a7-c2be-4c3a-a9b2-36d5fd2f60d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (10.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pallavi\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a011cde-d635-4d28-adc0-5a412b6d6367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55d1aba7-b6eb-4e95-b13c-0ca22e42f28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e39b0ceb-bf9a-4d0d-9f9b-42d1b09d026f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PALLAVI\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46139062-a958-4227-a552-5e81706e8cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c4deeab4-c32d-4ffe-b094-7d7d3aa25048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PALLAVI\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "ann.add(Dense(6,input_dim = 7,activation=\"relu\",kernel_regularizer=l2(l2=0.01)))\n",
    "ann.add(Dense(5, activation=\"relu\",kernel_regularizer=l2(l2=0.01)))\n",
    "ann.add(Dense(4, activation=\"relu\",kernel_regularizer=l2(l2=0.01)))\n",
    "ann.add(Dense(3, activation=\"relu\",kernel_regularizer=l2(l2=0.01)))\n",
    "ann.add(Dense(2, activation=\"relu\",kernel_regularizer=l2(l2=0.01)))\n",
    "ann.add(Dense(1, activation=\"sigmoid\",kernel_regularizer=l2(l2=0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "76a16ce7-fe58-4035-a810-cff9fb24685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9cdbefab-6626-4ffc-a3b9-60e2367b12a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (8000, 7)\n",
      "y_train shape: (8000,)\n",
      "x_test shape: (2000, 7)\n",
      "y_test shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee9523b-a37c-4f4d-a8c6-2243a4f345be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "93c1570d-9e16-4386-af12-76aff19a2fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.7945 - loss: 0.7963 - val_accuracy: 0.8035 - val_loss: 0.7190\n",
      "Epoch 2/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7945 - loss: 0.6697 - val_accuracy: 0.8035 - val_loss: 0.6254\n",
      "Epoch 3/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7945 - loss: 0.6229 - val_accuracy: 0.8035 - val_loss: 0.5999\n",
      "Epoch 4/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.6018 - val_accuracy: 0.8035 - val_loss: 0.5816\n",
      "Epoch 5/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7945 - loss: 0.5856 - val_accuracy: 0.8035 - val_loss: 0.5674\n",
      "Epoch 6/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5732 - val_accuracy: 0.8035 - val_loss: 0.5565\n",
      "Epoch 7/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5637 - val_accuracy: 0.8035 - val_loss: 0.5482\n",
      "Epoch 8/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5562 - val_accuracy: 0.8035 - val_loss: 0.5416\n",
      "Epoch 9/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5503 - val_accuracy: 0.8035 - val_loss: 0.5363\n",
      "Epoch 10/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5457 - val_accuracy: 0.8035 - val_loss: 0.5321\n",
      "Epoch 11/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5419 - val_accuracy: 0.8035 - val_loss: 0.5287\n",
      "Epoch 12/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7945 - loss: 0.5388 - val_accuracy: 0.8035 - val_loss: 0.5260\n",
      "Epoch 13/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7945 - loss: 0.5362 - val_accuracy: 0.8035 - val_loss: 0.5235\n",
      "Epoch 14/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5340 - val_accuracy: 0.8035 - val_loss: 0.5214\n",
      "Epoch 15/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5320 - val_accuracy: 0.8035 - val_loss: 0.5196\n",
      "Epoch 16/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7945 - loss: 0.5303 - val_accuracy: 0.8035 - val_loss: 0.5179\n",
      "Epoch 17/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5288 - val_accuracy: 0.8035 - val_loss: 0.5165\n",
      "Epoch 18/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7945 - loss: 0.5275 - val_accuracy: 0.8035 - val_loss: 0.5152\n",
      "Epoch 19/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5262 - val_accuracy: 0.8035 - val_loss: 0.5141\n",
      "Epoch 20/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7945 - loss: 0.5251 - val_accuracy: 0.8035 - val_loss: 0.5130\n",
      "Epoch 21/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5241 - val_accuracy: 0.8035 - val_loss: 0.5120\n",
      "Epoch 22/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5231 - val_accuracy: 0.8035 - val_loss: 0.5110\n",
      "Epoch 23/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5221 - val_accuracy: 0.8035 - val_loss: 0.5101\n",
      "Epoch 24/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7945 - loss: 0.5213 - val_accuracy: 0.8035 - val_loss: 0.5091\n",
      "Epoch 25/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5205 - val_accuracy: 0.8035 - val_loss: 0.5084\n",
      "Epoch 26/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7945 - loss: 0.5197 - val_accuracy: 0.8035 - val_loss: 0.5077\n",
      "Epoch 27/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5190 - val_accuracy: 0.8035 - val_loss: 0.5069\n",
      "Epoch 28/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5183 - val_accuracy: 0.8035 - val_loss: 0.5063\n",
      "Epoch 29/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5176 - val_accuracy: 0.8035 - val_loss: 0.5055\n",
      "Epoch 30/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5171 - val_accuracy: 0.8035 - val_loss: 0.5050\n",
      "Epoch 31/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7945 - loss: 0.5165 - val_accuracy: 0.8035 - val_loss: 0.5044\n",
      "Epoch 32/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5159 - val_accuracy: 0.8035 - val_loss: 0.5039\n",
      "Epoch 33/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5154 - val_accuracy: 0.8035 - val_loss: 0.5035\n",
      "Epoch 34/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5150 - val_accuracy: 0.8035 - val_loss: 0.5031\n",
      "Epoch 35/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5146 - val_accuracy: 0.8035 - val_loss: 0.5026\n",
      "Epoch 36/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5142 - val_accuracy: 0.8035 - val_loss: 0.5023\n",
      "Epoch 37/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5138 - val_accuracy: 0.8035 - val_loss: 0.5018\n",
      "Epoch 38/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7945 - loss: 0.5134 - val_accuracy: 0.8035 - val_loss: 0.5014\n",
      "Epoch 39/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5131 - val_accuracy: 0.8035 - val_loss: 0.5010\n",
      "Epoch 40/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7945 - loss: 0.5128 - val_accuracy: 0.8035 - val_loss: 0.5008\n",
      "Epoch 41/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5125 - val_accuracy: 0.8035 - val_loss: 0.5004\n",
      "Epoch 42/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7945 - loss: 0.5123 - val_accuracy: 0.8035 - val_loss: 0.5003\n",
      "Epoch 43/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5120 - val_accuracy: 0.8035 - val_loss: 0.5000\n",
      "Epoch 44/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7945 - loss: 0.5118 - val_accuracy: 0.8035 - val_loss: 0.4997\n",
      "Epoch 45/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.5116 - val_accuracy: 0.8035 - val_loss: 0.4995\n",
      "Epoch 46/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7945 - loss: 0.5114 - val_accuracy: 0.8035 - val_loss: 0.4993\n",
      "Epoch 47/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7945 - loss: 0.5112 - val_accuracy: 0.8035 - val_loss: 0.4991\n",
      "Epoch 48/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7945 - loss: 0.5110 - val_accuracy: 0.8035 - val_loss: 0.4990\n",
      "Epoch 49/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7945 - loss: 0.5108 - val_accuracy: 0.8035 - val_loss: 0.4989\n",
      "Epoch 50/50\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7945 - loss: 0.5107 - val_accuracy: 0.8035 - val_loss: 0.4987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d1fb12bd40>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(x_train, y_train,batch_size=100,epochs=50, validation_data=(x_test,y_test),callbacks=[EarlyStopping(patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "65f1f9f2-8a70-41a3-8be3-55468f91dbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798,\n",
       "  0.7944999933242798],\n",
       " 'loss': [0.7962755560874939,\n",
       "  0.6697071194648743,\n",
       "  0.6229376196861267,\n",
       "  0.6018323302268982,\n",
       "  0.5856391787528992,\n",
       "  0.5732108354568481,\n",
       "  0.5636805891990662,\n",
       "  0.5562472939491272,\n",
       "  0.5503356456756592,\n",
       "  0.5457276701927185,\n",
       "  0.5418863296508789,\n",
       "  0.5387906432151794,\n",
       "  0.5361648797988892,\n",
       "  0.5339725613594055,\n",
       "  0.5320230722427368,\n",
       "  0.5303248167037964,\n",
       "  0.5288138389587402,\n",
       "  0.5274523496627808,\n",
       "  0.5262170433998108,\n",
       "  0.5250760316848755,\n",
       "  0.5240734815597534,\n",
       "  0.5230997800827026,\n",
       "  0.5221220254898071,\n",
       "  0.5212883353233337,\n",
       "  0.5204654335975647,\n",
       "  0.5196546912193298,\n",
       "  0.5189560055732727,\n",
       "  0.5182653069496155,\n",
       "  0.517622709274292,\n",
       "  0.5170732736587524,\n",
       "  0.5164685249328613,\n",
       "  0.5159376859664917,\n",
       "  0.5154346227645874,\n",
       "  0.5150060057640076,\n",
       "  0.5146176815032959,\n",
       "  0.5142059326171875,\n",
       "  0.5137826204299927,\n",
       "  0.5134351253509521,\n",
       "  0.5131205916404724,\n",
       "  0.5128141045570374,\n",
       "  0.5125213861465454,\n",
       "  0.5122891664505005,\n",
       "  0.5119850635528564,\n",
       "  0.511795699596405,\n",
       "  0.5115659236907959,\n",
       "  0.5114402174949646,\n",
       "  0.5111767053604126,\n",
       "  0.5110113024711609,\n",
       "  0.5108320713043213,\n",
       "  0.5106925964355469],\n",
       " 'val_accuracy': [0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399,\n",
       "  0.8034999966621399],\n",
       " 'val_loss': [0.7190172076225281,\n",
       "  0.6253701448440552,\n",
       "  0.5998613238334656,\n",
       "  0.581554114818573,\n",
       "  0.5673895478248596,\n",
       "  0.5565129518508911,\n",
       "  0.5482186675071716,\n",
       "  0.5415734052658081,\n",
       "  0.5363255143165588,\n",
       "  0.5320718884468079,\n",
       "  0.5286585688591003,\n",
       "  0.5259840488433838,\n",
       "  0.5234607458114624,\n",
       "  0.5213534832000732,\n",
       "  0.5195589661598206,\n",
       "  0.5179389119148254,\n",
       "  0.5165230631828308,\n",
       "  0.5152332186698914,\n",
       "  0.5141241550445557,\n",
       "  0.5130359530448914,\n",
       "  0.5120290517807007,\n",
       "  0.5109727382659912,\n",
       "  0.5100812315940857,\n",
       "  0.5091168284416199,\n",
       "  0.5083546042442322,\n",
       "  0.5076619386672974,\n",
       "  0.5068673491477966,\n",
       "  0.5063260793685913,\n",
       "  0.5055404305458069,\n",
       "  0.5049695372581482,\n",
       "  0.5043760538101196,\n",
       "  0.5039043426513672,\n",
       "  0.5034582614898682,\n",
       "  0.5030771493911743,\n",
       "  0.5026063323020935,\n",
       "  0.5022591352462769,\n",
       "  0.5017895102500916,\n",
       "  0.501427173614502,\n",
       "  0.5010420680046082,\n",
       "  0.5008191466331482,\n",
       "  0.5004469156265259,\n",
       "  0.5002871751785278,\n",
       "  0.49997058510780334,\n",
       "  0.49973565340042114,\n",
       "  0.499538779258728,\n",
       "  0.49931830167770386,\n",
       "  0.49914196133613586,\n",
       "  0.49900591373443604,\n",
       "  0.49890562891960144,\n",
       "  0.49869590997695923]}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "085a4921-79cd-4500-858a-15258777e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = ann.history.history[\"accuracy\"]\n",
    "test_accuracy = ann.history.history[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d88f09b9-3cf7-4722-ab0d-a9959bfa8447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 51), train_accuracy, c='blue', label='Train Accuracy', marker='o')\n",
    "plt.plot(range(1, 51), test_accuracy, c='red', label='Test Accuracy', marker='x')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c72a62b2-f7c3-46cd-b7a9-bb3987c3dc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "pr1 = ann.predict(x_train)\n",
    "prd_data1 = []\n",
    "for i in pr1:\n",
    "    if i[0] > 0.5:\n",
    "        prd_data1.append(1)\n",
    "    else:\n",
    "        prd_data1.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e1573fe8-b9fa-4f6d-9b22-19ada4380fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    }
   ],
   "source": [
    "pr = ann.predict(x_test)\n",
    "prd_data = []\n",
    "for i in pr:\n",
    "    if i[0] > 0.5:\n",
    "        prd_data.append(1)\n",
    "    else:\n",
    "        prd_data.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1482ea77-fc58-4b8e-9271-f52922697a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fd992728-40cd-4813-867f-f736176f6dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "af74cde7-9f10-4a98-9261-cead9fac7c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.650000000000002"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,prd_data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "daadd213-ff3a-49a3-9822-901e324c139f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.549999999999997"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,prd_data1)*100   \n",
    "# training accuracy > testing accuracy (overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54be3704-2a5b-4d51-9814-5b9c88c8a4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
